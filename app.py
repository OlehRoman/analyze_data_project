import streamlit as st
from streamlit_folium import st_folium
import pandas as pd
import numpy as np
import folium
from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from prophet import Prophet
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- 1. –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø –°–¢–û–†–Ü–ù–ö–ò (–ú–∞—î –±—É—Ç–∏ –ø–µ—Ä—à–∏–º) ---
st.set_page_config(page_title="–ê–Ω–∞–ª—ñ–∑ –î–¢–ü –õ—å–≤—ñ–≤", layout="wide", page_icon="üöó")


# --- 2. –§–£–ù–ö–¶–Ü–á –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• ---
@st.cache_data
def load_main_data():
    df = pd.read_csv('accident_clear_data.csv', sep=';')

    def clean_accident_cause_final(val):
        val = str(val).lower()
        if '–Ω–µ—Ç–≤–µ—Ä–µ–∑–æ–º—É' in val or '—Å–ø\'—è–Ω—ñ–Ω–Ω—è' in val or '–∞–ª–∫–æ–≥–æ–ª—å' in val:
            return '–ê–ª–∫–æ–≥–æ–ª—å'
        elif '—à–≤–∏–¥–∫–æ—Å—Ç' in val:
            return '–®–≤–∏–¥–∫—ñ—Å—Ç—å'
        elif '–ø—ñ—à–æ—Ö—ñ–¥' in val or '–ø–µ—Ä–µ—Ö–æ–¥' in val or '–Ω–µ–≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ–º—É' in val:
            return '–ü—ñ—à–æ—Ö—ñ–¥'
        elif '–ø–µ—Ä–µ—Ö—Ä–µ—Å—Ç' in val or '–ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç' in val or '—Å–≤—ñ—Ç–ª–æ—Ñ–æ—Ä' in val:
            return '–ü–µ—Ä–µ—Ö—Ä–µ—Å—Ç—è/–°–≤—ñ—Ç–ª–æ—Ñ–æ—Ä'
        elif '–º–∞–Ω–µ–≤—Ä—É–≤–∞–Ω–Ω—è' in val or '—Ä–æ–∑–≤–æ—Ä–æ—Ç' in val:
            return '–ú–∞–Ω–µ–≤—Ä—É–≤–∞–Ω–Ω—è'
        elif '–æ–±–≥—ñ–Ω' in val or '–∑—É—Å—Ç—Ä—ñ—á–Ω' in val:
            return '–û–±–≥—ñ–Ω/–ó—É—Å—Ç—Ä—ñ—á–∫–∞'
        elif '–¥–∏—Å—Ç–∞–Ω—Ü' in val:
            return '–î–∏—Å—Ç–∞–Ω—Ü—ñ—è'
        elif '–Ω–µ–≤—ñ–¥–æ–º–æ' in val:
            return '–ù–µ–≤—ñ–¥–æ–º–æ'
        else:
            return '–Ü–Ω—à–µ'

    df['Simple_Cause'] = df['mainAccidentCause'].apply(clean_accident_cause_final)
    return df


@st.cache_data
def load_prophet_data():
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è 3-—ó —á–∞—Å—Ç–∏–Ω–∏ (Prophet)
    # –Ø–∫—â–æ —Ñ–∞–π–ª —Ç–æ–π —Å–∞–º–∏–π, –º–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ load_main_data,
    # –∞–ª–µ —É —Ç–≤–æ—î–º—É –∫–æ–¥—ñ –±—É–≤ 'combined_accidents.csv'
    try:
        df = pd.read_csv('combined_accidents.csv', sep=';')
    except FileNotFoundError:
        # Fallback —è–∫—â–æ —Ñ–∞–π–ª–∏ –æ–¥–Ω–∞–∫–æ–≤—ñ
        df = pd.read_csv('accident_clear_data.csv', sep=';')
    return df


# --- 3. –ù–ê–í–Ü–ì–ê–¶–Ü–Ø ---
st.sidebar.title("üóÇÔ∏è –ú–µ–Ω—é")
page = st.sidebar.radio("–û–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª:",
                        ["üó∫Ô∏è –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –∫–∞—Ä—Ç–∞", "üìä –ê–Ω–∞–ª—ñ–∑ —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ (ML)", "üìà –ü—Ä–æ–≥–Ω–æ–∑ (Prophet)"])

# ==============================================================================
# –°–¢–û–†–Ü–ù–ö–ê 1: –Ü–ù–¢–ï–†–ê–ö–¢–ò–í–ù–ê –ö–ê–†–¢–ê (–¢–≤—ñ–π –ø–µ—Ä—à–∏–π —Ñ–∞–π–ª)
# ==============================================================================
if page == "üó∫Ô∏è –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –∫–∞—Ä—Ç–∞":
    st.title("üó∫Ô∏è –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞ –∫–∞—Ä—Ç–∞ –î–¢–ü —É –õ—å–≤–æ–≤—ñ")
    st.markdown("–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü—ñ—è –∞–≤–∞—Ä—ñ–π–Ω–æ-–Ω–µ–±–µ–∑–ø–µ—á–Ω–∏—Ö –¥—ñ–ª—è–Ω–æ–∫ (DBSCAN).")

    df = load_main_data()

    st.sidebar.header("üîç –§—ñ–ª—å—Ç—Ä–∏ –∫–∞—Ä—Ç–∏")
    if 'Year' in df.columns:
        years = sorted(df['Year'].unique())
        selected_years = st.sidebar.slider("–†–æ–∫–∏", min(years), max(years), (min(years), max(years)))
        df_filtered = df[(df['Year'] >= selected_years[0]) & (df['Year'] <= selected_years[1])]
    else:
        df_filtered = df.copy()

    hour_range = st.sidebar.slider("–ß–∞—Å –¥–æ–±–∏", 0, 23, (0, 23))
    df_filtered = df_filtered[(df_filtered['Hour'] >= hour_range[0]) & (df_filtered['Hour'] <= hour_range[1])]

    all_causes = sorted(df['Simple_Cause'].unique())
    selected_causes = st.sidebar.multiselect("–ü—Ä–∏—á–∏–Ω–∏", all_causes, default=all_causes)
    df_filtered = df_filtered[df_filtered['Simple_Cause'].isin(selected_causes)]

    st.sidebar.markdown("---")
    eps_meters = st.sidebar.slider("–†–∞–¥—ñ—É—Å (–º)", 20, 200, 70)
    min_samples = st.sidebar.slider("–ú—ñ–Ω. –∞–≤–∞—Ä—ñ–π", 2, 20, 5)

    if len(df_filtered) > 0:
        coords = df_filtered[['latitude', 'longitude']].values
        coords_rad = np.radians(coords)
        kms_per_radian = 6371.0
        epsilon = (eps_meters / 1000) / kms_per_radian

        db = DBSCAN(eps=epsilon, min_samples=min_samples, metric='haversine', algorithm='ball_tree').fit(coords_rad)
        df_filtered['Cluster'] = db.labels_

        total_accidents = len(df_filtered)
        noise_count = np.sum(df_filtered['Cluster'] == -1)
        clustered_count = total_accidents - noise_count
        noise_percent = (noise_count / total_accidents) * 100
        clusters_found = len(set(db.labels_)) - (1 if -1 in db.labels_ else 0)

        # –ú–µ—Ç—Ä–∏–∫–∏
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("–í—Å—å–æ–≥–æ –î–¢–ü", total_accidents)
        c2.metric("–ó–æ–Ω –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü—ñ—ó", clusters_found, f"{clustered_count} –∞–≤–∞—Ä—ñ–π")
        c3.metric("–®—É–º (–ø–æ–æ–¥–∏–Ω–æ–∫—ñ)", f"{noise_percent:.1f}%")
        avg_acc = clustered_count / clusters_found if clusters_found > 0 else 0
        c4.metric("–°–µ—Ä. –î–¢–ü –Ω–∞ –∑–æ–Ω—É", f"{avg_acc:.1f}")

        # –ö–∞—Ä—Ç–∞
        cluster_stats = df_filtered[df_filtered['Cluster'] != -1].groupby('Cluster').agg({
            'latitude': 'mean', 'longitude': 'mean',
            'Simple_Cause': lambda x: x.mode()[0] if not x.mode().empty else '–Ü–Ω—à–µ',
            'accidentDay': 'count'
        }).rename(columns={'accidentDay': 'AccidentCount'})

        m = folium.Map(location=[49.8397, 24.0297], zoom_start=12)
        colors = {'–®–≤–∏–¥–∫—ñ—Å—Ç—å': 'red', '–ê–ª–∫–æ–≥–æ–ª—å': 'black', '–ü–µ—Ä–µ—Ö—Ä–µ—Å—Ç—è/–°–≤—ñ—Ç–ª–æ—Ñ–æ—Ä': 'orange',
                  '–ü—ñ—à–æ—Ö—ñ–¥': 'purple', '–ú–∞–Ω–µ–≤—Ä—É–≤–∞–Ω–Ω—è': 'blue', '–û–±–≥—ñ–Ω/–ó—É—Å—Ç—Ä—ñ—á–∫–∞': 'darkred',
                  '–î–∏—Å—Ç–∞–Ω—Ü—ñ—è': 'cadetblue', '–ù–µ–≤—ñ–¥–æ–º–æ': 'lightgray', '–Ü–Ω—à–µ': 'green'}

        for cid, row in cluster_stats.iterrows():
            cause = row['Simple_Cause']
            color = colors.get(cause, 'gray')
            radius = min(6 + (np.log1p(row['AccidentCount']) * 4), 25)
            folium.CircleMarker(
                [row['latitude'], row['longitude']], radius=radius, color=color, fill=True, fill_color=color,
                fill_opacity=0.7,
                tooltip=f"{cause}: {row['AccidentCount']}"
            ).add_to(m)

        st_folium(m, width=1000, height=600)
        st.write("### –î–µ—Ç–∞–ª—ñ –ø–æ –∑–æ–Ω–∞—Ö")
        st.dataframe(cluster_stats.sort_values(by='AccidentCount', ascending=False), use_container_width=True)
    else:
        st.warning("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è.")

# ==============================================================================
# –°–¢–û–†–Ü–ù–ö–ê 2: –ê–ù–ê–õ–Ü–ó –§–ê–ö–¢–û–†–Ü–í (–¢–≤—ñ–π –¥—Ä—É–≥–∏–π —Ñ–∞–π–ª)
# ==============================================================================
elif page == "üìä –ê–Ω–∞–ª—ñ–∑ —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ (ML)":
    st.title("üìä –ê–Ω–∞–ª—ñ–∑ —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ —Ç—è–∂–∫–æ—Å—Ç—ñ –î–¢–ü")
    st.markdown("–í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è **Random Forest** –¥–ª—è –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –ø—Ä–∏—á–∏–Ω —Ç—è–∂–∫–∏—Ö –Ω–∞—Å–ª—ñ–¥–∫—ñ–≤.")

    df = load_main_data()

    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
    df['Is_Severe'] = (df['Count_–¢—è–∂–∫–æ —Ç—Ä–∞–≤–º–æ–≤–∞–Ω–∏–π'] + df['Count_–ó–∞–≥–∏–Ω—É–≤']) > 0
    df['Is_Severe'] = df['Is_Severe'].astype(int)

    st.write("#### 1. –†–æ–∑–ø–æ–¥—ñ–ª —Ç—è–∂–∫–æ—Å—Ç—ñ")
    counts = df['Is_Severe'].value_counts()
    c1, c2 = st.columns(2)
    c1.metric("–õ–µ–≥–∫—ñ –î–¢–ü (0)", counts.get(0, 0))
    c2.metric("–¢—è–∂–∫—ñ/–°–º–µ—Ä—Ç–µ–ª—å–Ω—ñ (1)", counts.get(1, 0))

    if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ"):
        with st.spinner('–ù–∞–≤—á–∞–Ω–Ω—è Random Forest...'):
            feature_cols = ['Hour', 'DayOfWeek', 'Month', 'district', 'Simple_Cause']
            X = df[feature_cols].copy()
            y = df['Is_Severe']

            encoders = {}
            for col in ['district', 'Simple_Cause']:
                le = LabelEncoder()
                X[col] = le.fit_transform(X[col].astype(str))
                encoders[col] = le

            rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
            rf.fit(X, y)
        st.success("–ú–æ–¥–µ–ª—å –Ω–∞–≤—á–µ–Ω–æ!")

        # –ì—Ä–∞—Ñ—ñ–∫ 1: Feature Importance
        st.subheader("–¢–æ–ø —Ñ–∞–∫—Ç–æ—Ä—ñ–≤ –≤–ø–ª–∏–≤—É")
        importances = rf.feature_importances_
        fi_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances}).sort_values(by='Importance',
                                                                                            ascending=False)

        fig1, ax1 = plt.subplots(figsize=(10, 6))
        sns.barplot(x='Importance', y='Feature', data=fi_df, palette='viridis', ax=ax1)
        st.pyplot(fig1)

        # –ì—Ä–∞—Ñ—ñ–∫ 2: Heatmap
        st.subheader("–ú–∞–ø–∞ –Ω–µ–±–µ–∑–ø–µ–∫–∏ –∑–∞ —á–∞—Å–æ–º")
        pivot = df.pivot_table(index='DayOfWeek', columns='Hour', values='Is_Severe', aggfunc='mean')
        days_ua = ['–ü–æ–Ω–µ–¥—ñ–ª–æ–∫', '–í—ñ–≤—Ç–æ—Ä–æ–∫', '–°–µ—Ä–µ–¥–∞', '–ß–µ—Ç–≤–µ—Ä', '–ü\'—è—Ç–Ω–∏—Ü—è', '–°—É–±–æ—Ç–∞', '–ù–µ–¥—ñ–ª—è']

        fig2, ax2 = plt.subplots(figsize=(12, 5))
        sns.heatmap(pivot, cmap='Reds', yticklabels=days_ua, ax=ax2)
        st.pyplot(fig2)

    st.markdown("---")
    st.subheader("–î–µ—Ç–∞–ª—å–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –Ω–µ–±–µ–∑–ø–µ–∫–∏")

    # –ú—É–ª—å—Ç–∏-–ª–µ–π–±–ª–∏
    df_exploded = df.copy()
    df_exploded['mainAccidentCause'] = df_exploded['mainAccidentCause'].astype(str).apply(lambda x: x.split(', '))
    df_exploded = df_exploded.explode('mainAccidentCause')
    df_exploded['mainAccidentCause'] = df_exploded['mainAccidentCause'].str.strip()

    min_accidents = 20
    stats = df_exploded.groupby('mainAccidentCause')['Is_Severe'].agg(['count', 'mean'])
    stats = stats[stats['count'] >= min_accidents]
    stats['severity_pct'] = stats['mean'] * 100
    stats = stats.sort_values(by='severity_pct', ascending=False)

    # –ì—Ä–∞—Ñ—ñ–∫ 3
    fig3, ax3 = plt.subplots(figsize=(12, 8))
    avg_sev = df['Is_Severe'].mean() * 100
    colors = ['#d62728' if x > avg_sev else '#7f7f7f' for x in stats['severity_pct']]
    sns.barplot(x=stats['severity_pct'], y=stats.index, palette=colors, ax=ax3)
    ax3.axvline(x=avg_sev, color='black', linestyle='--')
    ax3.text(avg_sev + 0.5, len(stats) - 1, f'–°–µ—Ä–µ–¥–Ω—î: {avg_sev:.1f}%')
    st.pyplot(fig3)

    st.write("#### –¢–∞–±–ª–∏—á–Ω—ñ –¥–∞–Ω—ñ")
    st.dataframe(stats)

# ==============================================================================
# –°–¢–û–†–Ü–ù–ö–ê 3: –ü–†–û–ì–ù–û–ó (–¢–≤—ñ–π —Ç—Ä–µ—Ç—ñ–π —Ñ–∞–π–ª)
# ==============================================================================
elif page == "üìà –ü—Ä–æ–≥–Ω–æ–∑ (Prophet)":
    st.title("üìà –ü—Ä–æ–≥–Ω–æ–∑ –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –î–¢–ü")
    st.markdown("–ß–∞—Å–æ–≤—ñ —Ä—è–¥–∏ —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ **Prophet**.")

    df_prophet = load_prophet_data()

    # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞
    if 'accidentDate' in df_prophet.columns:
        df_prophet['Date'] = pd.to_datetime(df_prophet['accidentDate'])
    else:
        st.error("–£ —Ñ–∞–π–ª—ñ CSV –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ 'accidentDate'")
        st.stop()

    daily_df = df_prophet.groupby('Date').size().reset_index(name='y')
    daily_df.columns = ['ds', 'y']

    st.write(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –¥–∞–Ω–∏—Ö –∑–∞ {len(daily_df)} –¥–Ω—ñ–≤.")

    periods = st.slider("–ù–∞ —Å–∫—ñ–ª—å–∫–∏ –¥–Ω—ñ–≤ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞—Ç–∏ –≤–ø–µ—Ä–µ–¥?", 7, 365, 30)

    if st.button("üîÆ –°–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø—Ä–æ–≥–Ω–æ–∑"):
        with st.spinner('–¢—Ä–µ–Ω—É—î–º–æ Prophet... –¶–µ –º–æ–∂–µ –∑–∞–π–Ω—è—Ç–∏ —Ö–≤–∏–ª–∏–Ω—É.'):
            # –ú–æ–¥–µ–ª—å –Ω–∞ –≤—Å—ñ—Ö –¥–∞–Ω–∏—Ö
            m = Prophet(weekly_seasonality=True, yearly_seasonality=True)
            m.add_country_holidays(country_name='UA')
            m.fit(daily_df)

            future = m.make_future_dataframe(periods=periods)
            forecast = m.predict(future)

        st.success("–ü—Ä–æ–≥–Ω–æ–∑ –≥–æ—Ç–æ–≤–∏–π!")

        # –ì—Ä–∞—Ñ—ñ–∫ 1
        st.subheader("–¢—Ä–µ–Ω–¥ —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑")
        fig1 = m.plot(forecast)
        st.pyplot(fig1)

        # –ì—Ä–∞—Ñ—ñ–∫ 2
        st.subheader("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ (–°–µ–∑–æ–Ω–Ω—ñ—Å—Ç—å)")
        fig2 = m.plot_components(forecast)
        st.pyplot(fig2)

        # –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –ø–µ—Ä—ñ–æ–¥—ñ (–æ—Å—Ç–∞–Ω–Ω—ñ 30 –¥–Ω—ñ–≤ –∑ —ñ—Å—Ç–æ—Ä—ñ—ó)
        st.markdown("---")
        st.write("### –û—Ü—ñ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç—ñ (Backtesting)")
        test_days = 30
        train_df = daily_df.iloc[:-test_days]
        test_df = daily_df.iloc[-test_days:]

        m_test = Prophet(weekly_seasonality=True, yearly_seasonality=True)
        m_test.add_country_holidays(country_name='UA')
        m_test.fit(train_df)
        forecast_test = m_test.predict(test_df)

        y_true = test_df['y'].values
        y_pred = forecast_test['yhat'].values

        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))

        c1, c2, c3 = st.columns(3)
        c1.metric("MAE (–ü–æ–º–∏–ª–∫–∞)", f"{mae:.2f}")
        c2.metric("RMSE", f"{rmse:.2f}")
        c3.metric("–°–µ—Ä–µ–¥–Ω—î –î–¢–ü/–¥–µ–Ω—å", f"{daily_df['y'].mean():.2f}")